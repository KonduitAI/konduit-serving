{"@type": "InferenceConfiguration", "steps": [{"@type": "ModelStep", "inputNames": ["IteratorGetNext:0", "IteratorGetNext:1", "IteratorGetNext:4"], "outputNames": ["loss/Softmax"], "modelConfig": {"@type": "TensorFlowConfig", "tensorDataTypesConfig": {"@type": "TensorDataTypesConfig", "inputDataTypes": {"IteratorGetNext:0": "INT32", "IteratorGetNext:1": "INT32", "IteratorGetNext:4": "INT32"}}, "modelConfigType": {"@type": "ModelConfigType", "modelType": "TENSORFLOW", "modelLoadingPath": "bert_mrpc_frozen.pb"}}, "parallelInferenceConfig": {"@type": "ParallelInferenceConfig", "workers": 1}}], "servingConfig": {"@type": "ServingConfig", "httpPort": 5337, "inputDataFormat": "NUMPY", "outputDataFormat": "NUMPY", "predictionType": "RAW", "logTimings": true}}