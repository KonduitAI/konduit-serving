{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a python server\n",
    "\n",
    "A konduit python runner requires declaring and configuring a python pipeline step.\n",
    "This pipeline step can either be directly passed python code or a python code path.\n",
    "\n",
    "Optionally, one is also able to declare a python path to be passed and used in the python script.\n",
    "In our examples, we have a pre installed anaconda and use a custom python path to introduce\n",
    "custom dependencies.\n",
    "\n",
    "An example configuration is below: \n",
    "\n",
    "```json\n",
    "{\n",
    "  \"@type\": \"InferenceConfiguration\",\n",
    "  \"pipelineSteps\": [\n",
    "    {\n",
    "      \"@type\": \"PythonStep\",\n",
    "      \"inputColumnNames\": {\n",
    "        \"default\": [\n",
    "          \"img_path\"\n",
    "        ]\n",
    "      },\n",
    "      \"inputNames\": [\n",
    "        \"default\"\n",
    "      ],\n",
    "      \"inputSchemas\": {\n",
    "        \"default\": [\n",
    "          \"String\"\n",
    "        ]\n",
    "      },\n",
    "      \"outputColumnNames\": {\n",
    "        \"default\": [\n",
    "          \"label\",\n",
    "          \"proba\"\n",
    "        ]\n",
    "      },\n",
    "      \"outputNames\": [\n",
    "        \"default\"\n",
    "      ],\n",
    "      \"outputSchemas\": {\n",
    "        \"default\": [\n",
    "          \"String\",\n",
    "          \"String\"\n",
    "        ]\n",
    "      },\n",
    "      \"pythonConfigs\": {\n",
    "        \"default\": {\n",
    "          \"@type\": \"PythonConfig\",\n",
    "          \"pythonCodePath\": \"/usr/share/input-data/exec.py\",\n",
    "          \"pythonInputs\": {\n",
    "            \"img_path\": \"STR\"\n",
    "          },\n",
    "          \"pythonOutputs\": {\n",
    "            \"label\": \"STR\",\n",
    "            \"proba\": \"STR\"\n",
    "          },\n",
    "          \"pythonPath\": \"/opt/conda/lib/python37.zip:/opt/conda/lib/python3.7:/opt/conda/lib/python3.7/lib-dynload:/opt/conda/lib/python3.7/site-packages:/opt/conda/lib/python3.7/site-packages/konduitserving-0.1-py3.7.egg:/opt/conda/lib/python3.7/site-packages/pandas-0.24.2-py3.7-linux-x86_64.egg:/opt/conda/lib/python3.7/site-packages/requests_toolbelt-0.9.1-py3.7.egg:/opt/conda/lib/python3.7/site-packages/pyarrow-0.13.0-py3.7-linux-x86_64.egg:/opt/conda/lib/python3.7/site-packages/numpy-1.16.4-py3.7-linux-x86_64.egg:/opt/conda/lib/python3.7/site-packages/pytz-2019.2-py3.7.egg\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"servingConfig\": {\n",
    "    \"@type\": \"ServingConfig\",\n",
    "    \"httpPort\": 65535,\n",
    "    \"listenHost\": \"0.0.0.0\",\n",
    "    \"logTimings\": true,\n",
    "    \"parallelInferenceConfig\": {\n",
    "      \"@type\": \"ParallelInferenceConfig\",\n",
    "      \"workers\": 1\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "In the above example, we are running the below code which uses keras applications, downloads resnet and runs inference\n",
    "on a specified image path.\n",
    "\n",
    "The above json was generated using the konduit sdk, see below for an example:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konduit.inference import *\n",
    "from konduit.json_utils import json_with_type\n",
    "\n",
    "import random\n",
    "import json\n",
    "\n",
    "input_names = ['default']\n",
    "output_names = ['default']\n",
    "port = 65535\n",
    "parallel_inference_config = ParallelInferenceConfig(workers=1)\n",
    "serving_config = ServingConfig(http_port=port,\n",
    "                                   log_timings=True,\n",
    "                                   parallel_inference_config=parallel_inference_config)\n",
    "\n",
    "python_config = PythonConfig(\n",
    "        python_path=python_path,\n",
    "        python_code_path='\"/usr/share/exec.py',\n",
    "        python_inputs={'img_path': 'STR'},\n",
    "        python_outputs={'label': 'STR','proba':'FLOAT'}\n",
    ")\n",
    "\n",
    "python_pipeline_step = PythonStep(input_names=input_names,\n",
    "                                              output_names=output_names,  \n",
    "                                           input_schemas=({'default': ['String']}),\n",
    "                                           output_schemas=({'default': ['String','Float']}),\n",
    "                                           input_column_names={'default': ['img_path']},\n",
    "                                             output_column_names={'default': ['label','proba']},\n",
    "                                              python_configs={'default': python_config})\n",
    "\n",
    "inference = InferenceConfiguration(serving_config=serving_config,\n",
    "                                       pipeline_steps=[python_pipeline_step])\n",
    "\n",
    "\n",
    "json_config = json_with_type(inference)\n",
    "print(json.dumps(json_config, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the sys declaration here is to sync with the server's python run time.\n",
    "import sys\n",
    "sys.version = '3.7.3 | packaged by conda-forge | (default, Jul  1 2019, 21:52:21)\\n[GCC 7.3.0]'\n",
    "\n",
    "# Run the pythons cript\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "# needed when dealing with multi threading\n",
    "sess = tf.Session()\n",
    "keras.backend.set_session(sess)\n",
    "\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "#img_path = 'African_Bush_Elephant_1-783x1024.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x)\n",
    "decoded = decode_predictions(preds, top=3)[0]\n",
    "id,label,proba = decoded[0]\n",
    "proba = str(proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input data\n",
    "\n",
    "Of note here are a few things for configuration:\n",
    " \n",
    "The python script has an absolute path directory at /usr/share/input-data. This is a directory that is mounted in to the server\n",
    "from the host machine, take a look at each directory's docker-compose.yml\n",
    "An example declaration for ease of reference:\n",
    "\n",
    "```yaml\n",
    "pipeline:\n",
    "    image: konduit-serving-with-conda\n",
    "    ports:\n",
    "     - 65535:65535\n",
    "    volumes:\n",
    "     - ./input-data:/usr/share/input-data #here is the volume declaration\n",
    "    entrypoint:\n",
    "     - java\n",
    "     - -Dorg.bytedeco.javacpp.logger.debug=true\n",
    "     - -Dorg.bytedeco.javacpp.logger=slf4j\n",
    "     - -Dai.konduit.serving.python.javacpp.path.append=none\n",
    "     - -Dvertx.options.maxEventLoopExecuteTime=10000000000000\n",
    "     - -cp\n",
    "     - /srv/konduit.jar\n",
    "     - KonduitServingMain\n",
    "     - --configPath\n",
    "     - /usr/share/input-data/config.json # mounted\n",
    "```\n",
    "\n",
    "\n",
    "Everything else are just application specific and are mostly used for debugging purposes and can be ignored by most users.\n",
    "\n",
    "2. Look at the above configuration json again to see where else the /usr/share/input-data is used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customization\n",
    "\n",
    "To run your own python script, you need to setup a few things in the python step.\n",
    "\n",
    "* Input names/output names: This can generally be left alone as \"default\". This is generally used for more complex problems like multi input graphs.\n",
    "\n",
    "* Input schemas/Output Schemas: These are types of the variables for input and output. Available types can be found [here](https://github.com/KonduitAI/konduit-serving/blob/master/konduit-serving-api/src/main/java/ai/konduit/serving/config/SchemaType.java)\n",
    "\n",
    "* Python types: Python input types/output types are more specific to python. Python types can be found [here](https://github.com/KonduitAI/konduit-serving/blob/master/konduit-serving-python/src/main/java/ai/konduit/serving/util/python/PythonVariables.java#L46)\n",
    "\n",
    "* Mapping names and schemas: The types and variable names of the input output variables should \n",
    "be in the same order.\n",
    "\n",
    "* Ports: Note that we specify an http port above. The port will depend on the application, just make sure whatever you specify\n",
    "will not be used by other applications.\n",
    "\n",
    "* Custom python path: Go in to the python repl you want to use and type: \n",
    "```python\n",
    "import sys\n",
    "':'.join(sys.path)\n",
    "```\n",
    "\n",
    "for the correct value to put in the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
